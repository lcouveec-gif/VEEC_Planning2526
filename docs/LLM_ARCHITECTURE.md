# Architecture IA/LLM - Gestion s√©curis√©e par utilisateur

## üéØ Vue d'ensemble

L'application VEEC Planning int√®gre d√©sormais un syst√®me de configuration IA/LLM permettant √† chaque utilisateur de configurer ses propres param√®tres de mani√®re s√©curis√©e. Les cl√©s API sont chiffr√©es c√¥t√© serveur et jamais expos√©es au client.

## üèóÔ∏è Architecture

### Composants Frontend

#### 1. LLMConfig.tsx
**Emplacement** : `components/Admin/LLMConfig.tsx`

**Fonctionnalit√©s** :
- Configuration des param√®tres LLM par utilisateur
- Choix du provider (OpenAI, Anthropic, Google, Custom)
- S√©lection du mod√®le
- Saisie s√©curis√©e de la cl√© API (jamais affich√©e en clair)
- R√©glage temp√©rature et tokens max
- Test de connexion
- Synchronisation automatique entre appareils

**S√©curit√©** :
- V√©rification authentification obligatoire
- Cl√© API masqu√©e apr√®s sauvegarde
- Affichage message si utilisateur non connect√©

#### 2. WebhookManager.tsx
**Emplacement** : `components/Admin/WebhookManager.tsx`

**Fonctionnalit√©s** :
- Gestion des webhooks personnalis√©s
- Webhook pr√©d√©fini MajBaseMatch
- Ex√©cution et monitoring des webhooks

### Backend Supabase

#### 1. Table `user_llm_settings`

```sql
CREATE TABLE user_llm_settings (
  id uuid PRIMARY KEY,
  user_id uuid REFERENCES auth.users(id),
  provider text NOT NULL,
  api_key_encrypted text NOT NULL,  -- Chiffr√© avec pgcrypto
  model text NOT NULL,
  endpoint text NOT NULL,
  temperature numeric DEFAULT 0.7,
  max_tokens integer DEFAULT 2000,
  created_at timestamptz,
  updated_at timestamptz,
  UNIQUE(user_id)
);
```

**Row Level Security (RLS)** :
- Chaque utilisateur peut uniquement voir/modifier ses propres param√®tres
- Politiques SELECT, INSERT, UPDATE, DELETE activ√©es
- Authentification obligatoire via `auth.uid()`

#### 2. Edge Functions

##### a) save-llm-settings
**Endpoint** : `/functions/v1/save-llm-settings`

**M√©thode** : POST

**Body** :
```json
{
  "provider": "openai",
  "apiKey": "sk-...",
  "model": "gpt-4o",
  "endpoint": "https://api.openai.com/v1/chat/completions",
  "temperature": 0.7,
  "maxTokens": 2000
}
```

**Processus** :
1. V√©rifie l'authentification
2. Valide les donn√©es
3. Chiffre la cl√© API avec `pgp_sym_encrypt()`
4. Upsert dans `user_llm_settings`

**S√©curit√©** :
- Cl√© de chiffrement stock√©e dans les secrets Supabase
- Jamais expos√©e au client
- Chiffrement AES via pgcrypto

##### b) get-llm-settings
**Endpoint** : `/functions/v1/get-llm-settings`

**M√©thode** : GET

**R√©ponse** :
```json
{
  "settings": {
    "provider": "openai",
    "model": "gpt-4o",
    "endpoint": "https://api.openai.com/v1/chat/completions",
    "temperature": 0.7,
    "maxTokens": 2000,
    "hasApiKey": true,  // Indique si une cl√© existe
    "createdAt": "...",
    "updatedAt": "..."
  }
}
```

**S√©curit√©** :
- Cl√© API **jamais** retourn√©e
- Uniquement indicateur `hasApiKey`

##### c) call-llm
**Endpoint** : `/functions/v1/call-llm`

**M√©thode** : POST

**Body** :
```json
{
  "messages": [
    {"role": "user", "content": "Votre question"}
  ],
  "temperature": 0.7,  // Optionnel
  "maxTokens": 1000    // Optionnel
}
```

**Processus** :
1. V√©rifie l'authentification
2. R√©cup√®re et d√©chiffre les param√®tres de l'utilisateur
3. Appelle l'API LLM configur√©e
4. Normalise la r√©ponse selon le provider
5. Retourne le r√©sultat au client

**S√©curit√©** :
- Cl√© API d√©chiffr√©e uniquement c√¥t√© serveur
- Jamais expos√©e dans les logs ou r√©ponses
- Utilise la cl√© de l'utilisateur authentifi√©

## üîê S√©curit√©

### Chiffrement des cl√©s API

**M√©thode** : pgcrypto (PostgreSQL)

```sql
-- Chiffrement
pgp_sym_encrypt(api_key, encryption_key)

-- D√©chiffrement (uniquement serveur-side)
pgp_sym_decrypt(api_key_encrypted::bytea, encryption_key)
```

**Cl√© de chiffrement** :
- Stock√©e dans les secrets Supabase : `LLM_ENCRYPTION_KEY`
- Minimum 32 caract√®res
- G√©n√©r√©e al√©atoirement
- Jamais commit√©e dans le code

### Flow de s√©curit√©

```
Client (Browser)
    ‚Üì
    | 1. Saisie cl√© API
    ‚Üì
    | 2. Envoi HTTPS vers Edge Function
    ‚Üì
Supabase Edge Function
    ‚Üì
    | 3. Chiffrement avec LLM_ENCRYPTION_KEY
    ‚Üì
PostgreSQL (Supabase)
    ‚Üì
    | 4. Stockage cl√© chiffr√©e
    ‚Üì
RLS Policy
    | 5. V√©rification user_id = auth.uid()
```

### Appel LLM s√©curis√©

```
Client (Browser)
    ‚Üì
    | 1. Requ√™te call-llm (sans cl√© API)
    ‚Üì
Edge Function call-llm
    ‚Üì
    | 2. R√©cup√©ration user_id
    ‚Üì
    | 3. D√©chiffrement cl√© API (serveur uniquement)
    ‚Üì
API LLM (OpenAI/Anthropic/Google)
    ‚Üì
    | 4. R√©ponse LLM
    ‚Üì
Client (Browser)
    | 5. R√©sultat (jamais la cl√©)
```

## üìä Flux utilisateur

### Configuration initiale

1. Utilisateur se connecte √† l'application
2. Navigation : **Admin** > **IA / Automatisation**
3. Clic sur **Configurer** dans la carte Configuration LLM
4. S√©lection du provider (OpenAI, Anthropic, etc.)
5. Saisie de la cl√© API personnelle
6. R√©glage des param√®tres (temp√©rature, tokens)
7. Clic sur **Enregistrer**
8. Param√®tres chiffr√©s et sauvegard√©s dans Supabase

### Modification

1. Clic sur **Modifier**
2. Modification des param√®tres souhait√©s
3. Cl√© API masqu√©e (`‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢`)
4. Option : laisser vide pour conserver la cl√© actuelle
5. Clic sur **Enregistrer**

### Test de connexion

1. Bouton **Tester la connexion** (visible si param√®tres configur√©s)
2. Appel √† `call-llm` avec message de test
3. Affichage du r√©sultat (succ√®s ou erreur)

### Utilisation

1. Utilisateur utilise une fonctionnalit√© IA de l'app
2. Frontend appelle `call-llm` avec les messages
3. Serveur r√©cup√®re automatiquement les param√®tres de l'utilisateur
4. Appel au LLM avec la cl√© de l'utilisateur
5. R√©sultat retourn√© √† l'utilisateur

## üåê Synchronisation multi-appareils

**Avantage** : Les param√®tres sont li√©s au profil utilisateur, pas √† l'appareil.

**Sc√©nario** :
1. Utilisateur configure sur Desktop ‚Üí Sauvegarde dans Supabase
2. Se connecte sur Smartphone ‚Üí R√©cup√©ration automatique
3. Modification sur Smartphone ‚Üí Mise √† jour imm√©diate
4. Retour sur Desktop ‚Üí Param√®tres √† jour

## üîÑ Providers support√©s

### OpenAI
- Mod√®les : GPT-4o, GPT-4o-mini, GPT-4 Turbo, O1, etc.
- Endpoint : `https://api.openai.com/v1/chat/completions`
- Format : Bearer token

### Anthropic (Claude)
- Mod√®les : Claude 3.5 Sonnet, Claude 3.5 Haiku, etc.
- Endpoint : `https://api.anthropic.com/v1/messages`
- Format : x-api-key header

### Google (Gemini)
- Mod√®les : Gemini 2.5 Flash, Gemini 2.5 Pro, etc.
- Endpoint : `https://generativelanguage.googleapis.com/v1beta`
- Format : Query parameter

### Custom
- Endpoint personnalis√©
- Mod√®le personnalis√©
- Compatible avec APIs respectant le format OpenAI

## üìà √âvolutions futures

### Pr√©vues
- [ ] G√©n√©ration automatique de descriptions d'entra√Ænements
- [ ] Suggestions d'organisation de planning
- [ ] Analyse de disponibilit√©s des joueurs
- [ ] Assistant conversationnel dans le planning

### Possibles
- [ ] Quotas d'utilisation par utilisateur
- [ ] Logs d'utilisation IA
- [ ] Templates de prompts pr√©d√©finis
- [ ] Partage de configurations entre utilisateurs (optionnel)

## üõ†Ô∏è Maintenance

### Rotation de la cl√© de chiffrement

‚ö†Ô∏è **Attention** : N√©cessite un script de migration pour re-chiffrer toutes les cl√©s API.

1. G√©n√©rer nouvelle cl√©
2. D√©chiffrer toutes les cl√©s avec ancienne cl√©
3. Re-chiffrer avec nouvelle cl√©
4. Mettre √† jour le secret Supabase

### Monitoring

**M√©triques √† surveiller** :
- Nombre d'appels `call-llm` par utilisateur
- Taux d'erreur des Edge Functions
- Temps de r√©ponse des APIs LLM
- Co√ªts g√©n√©r√©s par les appels LLM

## üìö Documentation compl√©mentaire

- [Guide de d√©ploiement](../supabase/DEPLOYMENT_GUIDE.md)
- [Migrations SQL](../supabase/migrations/)
- [Edge Functions](../supabase/functions/)

## ü§ù Responsabilit√©s

### Utilisateur
- Fournit et g√®re sa propre cl√© API
- Responsable des co√ªts associ√©s √† son utilisation
- Doit respecter les conditions d'utilisation du provider

### Application
- Stockage s√©curis√© des cl√©s API
- Chiffrement/d√©chiffrement transparent
- Proxy pour les appels LLM
- Isolation des donn√©es entre utilisateurs

## ‚úÖ Conformit√©

- **RGPD** : Cl√©s API stock√©es de mani√®re chiffr√©e
- **S√©curit√©** : Row Level Security activ√©
- **Isolation** : Chaque utilisateur acc√®de uniquement √† ses donn√©es
- **Transparence** : Utilisateur contr√¥le sa cl√© API
